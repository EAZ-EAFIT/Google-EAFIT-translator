capítulo 5
Tornando os Transformers eficientes na produção UMA OBSERVAÇÃO PARA LEITORES DE LANÇAMENTO ANTERIOR Com os e-books de lançamento antecipado, você obtém os livros em sua forma mais antiga - o conteúdo bruto e não editado do autor enquanto eles escrevem - para que você possa aproveitar essas tecnologias muito antes do lançamento oficial desses títulos
Este será o 5º capítulo do último livro
Observe que o repositório do GitHub será ativado mais tarde
Se você tiver comentários sobre como podemos melhorar o conteúdo e/ou os exemplos deste livro, ou se notar falta de material neste capítulo, entre em contato com o editor em mpotter@oreilly
com
Nos capítulos anteriores, você viu como os Transformers podem ser ajustados para produzir ótimos resultados em uma ampla gama de tarefas.
No entanto, em muitas situações, a precisão (ou qualquer métrica para a qual você está otimizando) não é suficiente; seu modelo de última geração não é muito útil se for muito lento ou grande para atender aos requisitos de negócios de seu aplicativo
Uma alternativa óbvia é treinar um modelo mais rápido e compacto, mas a redução na capacidade do modelo geralmente é acompanhada por uma degradação no desempenho
Então, o que você pode fazer quando precisa de um modelo rápido, compacto, mas altamente preciso? e otimização de gráficos com o formato Open Neural NetworkExchange (ONNX) e ONNX Runtime (ORT)
Também veremos como algumas dessas técnicas podem ser combinadas para produzir ganhos significativos de desempenho
Por exemplo, essa foi a abordagem adotada pela equipe de engenharia da Roblox em seu artigo How We Scaled Bert To Serve 1+ Billion Daily Requests on CPUs, que mostrou na Figura 5-1 que a combinação de destilação de conhecimento e quantização permitiu que eles melhorassem a latência e o throughput de seu BERT classificador por mais de um fator de 30! Figura 5-1
Como a Roblox escalou o BERT com destilação de conhecimento, preenchimento dinâmico e quantização de peso (foto cortesia dos funcionários da Roblox Quoc N
Le e Kip Kaehler) Para ilustrar os benefícios e compensações associados a cada técnica, usaremos a detecção de intenção como um estudo de caso, pois é um componente importante de assistentes baseados em texto, onde baixas latências são críticas para manter uma conversa em tempo real
Ao longo do caminho, aprenderemos como criar treinadores personalizados, realizar pesquisas de hiperparâmetros eficientes e entender o que é necessário para implementar pesquisas de ponta com Transformers
Vamos nos aprofundar!Detecção de intenção como estudo de casoVamos supor que estamos tentando construir um assistente baseado em texto para o call center de nossa empresa, para que os clientes possam solicitar o saldo de sua conta ou fazer reservas sem precisar falar com um agente humano
Para entender os objetivos de um cliente, nosso assistente precisará ser capaz de classificar uma ampla variedade de textos em linguagem natural em um conjunto de ações ou intenções predefinidas
Por exemplo, um cliente pode enviar uma mensagem sobre uma próxima viagemOi, gostaria de alugar um veículo de 1º de novembro a 15 de novembro em Paris e preciso de uma van para 15 passageiros; então desencadeia uma ação e uma resposta
Para ser robusto em um ambiente de produção, nosso classificador também precisará ser capaz de lidar com consultas fora do escopo, como as mostradas no segundo e terceiro casos da Figura 5-2, em que um cliente faz uma consulta que não pertence a nenhum das intenções predefinidas e o sistema deve gerar uma resposta alternativa
Por exemplo, no segundo caso da Figura 5-2, um cliente faz uma pergunta sobre esporte que está fora do escopo e o assistente de texto a classifica erroneamente como uma das intenções dentro do escopo conhecidas, que é alimentada a um componente downstream que retorna a resposta do dia de pagamento
No terceiro caso, o assistente de texto foi treinado para detectar consultas fora do escopo (geralmente rotuladas como uma classe separada) e informa ao cliente sobre quais tópicos eles podem responder
Figura 5-2
Três trocas entre um humano (à direita) e um assistente baseado em texto (à esquerda) para finanças pessoais (cortesia de StefanLarson et al
